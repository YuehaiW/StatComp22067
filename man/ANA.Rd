% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/StatCompR.R
\name{ANA}
\alias{ANA}
\title{Approximate Newton Algorithm}
\usage{
ANA(
  stop.coef,
  L0,
  kk,
  omiga,
  lambda,
  sigma,
  elta,
  alpha_max,
  alpha_min,
  alpha_min_newton,
  epson,
  l,
  p,
  q,
  s
)
}
\arguments{
\item{stop.coef}{a stopping criteria for the algorithm to terminate while loop}

\item{L0}{the cholesky decomposition of the initial point}

\item{kk}{the l0 constraint, i.e. a maximally allowable number of nonzeros}

\item{omiga}{a sparsity constraint set which includes the indexes of variables known to be conditionally independent}

\item{lambda}{a regularization parameter}

\item{sigma}{a parameter takes value in (0,1) to ensure the stepsize is sufficiently small}

\item{elta}{a positive parameter to ensure the objective function value is sufficiently decreased}

\item{alpha_max}{the maximum stepsize for Newton's method}

\item{alpha_min}{the minimum stepsize for Newton's method}

\item{alpha_min_newton}{the first-order gradient of the objective function}

\item{epson}{the first-order gradient of the objective function}

\item{l}{the index of a decreased sequence}

\item{p}{the remainder of the iteration k mod q}

\item{q}{every q âˆ’ 1 iterations of the Newton steps we perform a single iteration of the gradient projection step}

\item{s}{the sample covariance}
}
\value{
the cholesky decompositon of the minimum point
}
\description{
an approximate Newton algorithm to compute the minimum point of the objective function
}
